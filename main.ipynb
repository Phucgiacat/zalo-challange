{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CneXQaKqQjw9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CneXQaKqQjw9",
        "outputId": "17887ccd-5173-48c8-c0c3-e4406e663186"
      },
      "outputs": [],
      "source": [
        "!pip install --q ultralytics supervision torch torchvision transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "n1g35B6BQly7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1g35B6BQly7",
        "outputId": "2ccff0eb-9af6-4dd4-d9da-fcfca4a29456"
      },
      "outputs": [],
      "source": [
        "!gdown --q --folder 1n98ur5MdsKuRtXTHkeM4PEwklBkDaJe4\n",
        "!unzip --q /content/Data/observing.zip\n",
        "!unzip --q /content/Data/public_test.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f15de4d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f15de4d0",
        "outputId": "6bd4f8f6-8818-4c0c-b7b2-94a11fed46fa",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# IMPORTS\n",
        "# ============================================\n",
        "\n",
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import yaml\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from scipy.interpolate import interp1d\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from ultralytics import YOLOWorld, YOLO\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec884357",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec884357",
        "outputId": "a1be418c-e2ad-4019-d650-d8a0a02a2aa1",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "# ============================================\n",
        "# CONFIGURATION (OPTIMIZED AND ENHANCED)\n",
        "# ============================================\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Configuration for training pipeline\"\"\"\n",
        "    # Dataset paths\n",
        "    DATASET_ROOT = \"train\"\n",
        "    ANNOTATIONS_PATH = os.path.join(DATASET_ROOT, \"annotations/annotations.json\")\n",
        "    SAMPLES_DIR = os.path.join(DATASET_ROOT, \"samples\")\n",
        "    WORK_DIR = \"enhanced_mixed_dataset_v2\"  # New directory\n",
        "\n",
        "    # Training settings\n",
        "    TRAIN_RATIO = 0.8\n",
        "    IMG_EXT = \"jpg\"\n",
        "    FRAME_STEP = 1\n",
        "    NUM_WORKERS = 8\n",
        "\n",
        "    # ========================================\n",
        "    # IMPORTANT CHANGE: Smaller model\n",
        "    # ========================================\n",
        "    MODEL_WEIGHTS = \"yolo12s.pt\"  # ~11M params base\n",
        "\n",
        "    # ALTERNATIVE STRATEGY:\n",
        "    # If 'yolov8s' still misses videos 3 & 4, try 'yolov8m' again\n",
        "    # (since it has seen them) and let HNM (code below) handle noise 5 & 6.\n",
        "    # MODEL_WEIGHTS = \"yolov8m-worldv2.pt\"\n",
        "    # ========================================\n",
        "\n",
        "    CLASS_NAMES = [\"target\"]\n",
        "\n",
        "    # Parameter limit\n",
        "    PARAM_LIMIT = 50_000_000  # 50M params limit\n",
        "\n",
        "    # Masked training settings\n",
        "    ENABLE_MASKING = True\n",
        "    NUM_AUGMENTATIONS_PER_PHASE = 2\n",
        "\n",
        "    # ========================================\n",
        "    # Hard Negative Mining settings\n",
        "    # ========================================\n",
        "    BACKGROUND_FRAME_RATIO = 0.1\n",
        "\n",
        "    # Curriculum Learning settings\n",
        "    CURRICULUM = {\n",
        "        'phase1': {'epochs': (0, 2), 'mask_ratio': 0.10, 'strategy': 'random'},\n",
        "        'phase2': {'epochs': (2, 5), 'mask_ratio': 0.20, 'strategy': 'random'},\n",
        "        'phase3': {'epochs': (5, 10), 'mask_ratio': 0.30, 'strategy': 'random'}\n",
        "    }\n",
        "\n",
        "config = Config()\n",
        "print(\"Configuration loaded (v2: HNM + Augmentations)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61ce2961",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61ce2961",
        "outputId": "311307cc-cfb0-4bae-dd6d-f3b710e3f5d1",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "# ============================================\n",
        "# MODEL OPTIMIZER CLASS\n",
        "# ============================================\n",
        "\n",
        "class ModelOptimizer:\n",
        "    \"\"\"Optimize YOLO World model\"\"\"\n",
        "\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def count_parameters(self):\n",
        "        \"\"\"Count number of parameters\"\"\"\n",
        "        model = self.model.model if hasattr(self.model, 'model') else self.model\n",
        "        total = sum(p.numel() for p in model.parameters())\n",
        "        trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "        return {'total': total, 'trainable': trainable, 'non_trainable': total - trainable}\n",
        "\n",
        "    def print_model_summary(self, stage=\"\"):\n",
        "        \"\"\"Print model statistics\"\"\"\n",
        "        params = self.count_parameters()\n",
        "        print(f\"\\n{'='*60}\\nMODEL STATISTICS {stage}\\n{'='*60}\")\n",
        "        print(f\"   Total params: {params['total']:,}\")\n",
        "        print(f\"   Trainable: {params['trainable']:,}\")\n",
        "        if params['total'] > config.PARAM_LIMIT:\n",
        "            print(f\"\\n   EXCEEDED LIMIT: {params['total'] - config.PARAM_LIMIT:,} params over\")\n",
        "        else:\n",
        "            print(f\"\\n   WITHIN LIMIT: {config.PARAM_LIMIT - params['total']:,} params remaining\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "        return params\n",
        "\n",
        "    def apply_magnitude_pruning(self, prune_ratio=0.3):\n",
        "        \"\"\"Magnitude-based pruning\"\"\"\n",
        "        print(f\"\\nApplying {prune_ratio*100:.0f}% Magnitude Pruning...\")\n",
        "        model = self.model.model if hasattr(self.model, 'model') else self.model\n",
        "        all_weights = []\n",
        "        for name, module in model.named_modules():\n",
        "            if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
        "                if hasattr(module, 'weight') and module.weight is not None:\n",
        "                    all_weights.append(module.weight.data.abs().flatten())\n",
        "        if not all_weights: \n",
        "            return\n",
        "        all_weights_tensor = torch.cat(all_weights)\n",
        "        threshold = torch.quantile(all_weights_tensor, prune_ratio)\n",
        "        pruned_count = 0\n",
        "        total_count = 0\n",
        "        for name, module in model.named_modules():\n",
        "            if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
        "                if hasattr(module, 'weight') and module.weight is not None:\n",
        "                    weight = module.weight.data\n",
        "                    mask = weight.abs() > threshold\n",
        "                    weight.mul_(mask)\n",
        "                    pruned_count += (~mask).sum().item()\n",
        "                    total_count += weight.numel()\n",
        "        print(f\"   Pruned {pruned_count:,} / {total_count:,} weights\")\n",
        "        return self.model\n",
        "\n",
        "print(\"Model optimizer class loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "307cb6fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "307cb6fd",
        "outputId": "b6f6f2d4-6232-4139-dec0-bcd14db0f391",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "# ============================================\n",
        "# 1. MASKING STRATEGIES\n",
        "# ============================================\n",
        "class FrameMaskingStrategy:\n",
        "    \"\"\"Strategies for masking frames to create self-supervised learning\"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def random_mask(total_frames, mask_ratio=0.3):\n",
        "        \"\"\"Randomly mask frames based on ratio\"\"\"\n",
        "        if total_frames < 3: \n",
        "            return []\n",
        "        num_mask = max(1, int(total_frames * mask_ratio))\n",
        "        num_mask = min(num_mask, total_frames - 2)\n",
        "        if num_mask <= 0: \n",
        "            return []\n",
        "        try:\n",
        "            return sorted(random.sample(range(1, total_frames-1), num_mask))\n",
        "        except ValueError: \n",
        "            return []\n",
        "\n",
        "    @staticmethod\n",
        "    def span_mask(total_frames, mask_ratio=0.3):\n",
        "        \"\"\"Mask continuous spans of frames\"\"\"\n",
        "        if total_frames < 5: \n",
        "            return FrameMaskingStrategy.random_mask(total_frames, mask_ratio)\n",
        "        span_length = max(2, int(total_frames * 0.1))\n",
        "        num_spans = max(1, int(total_frames * mask_ratio / span_length))\n",
        "        masked_indices = []\n",
        "        for _ in range(num_spans):\n",
        "            start = random.randint(1, max(2, total_frames - span_length - 1))\n",
        "            masked_indices.extend(range(start, min(start + span_length, total_frames-1)))\n",
        "        return sorted(list(set(masked_indices)))\n",
        "\n",
        "    @staticmethod\n",
        "    def keyframe_mask(frame_boxes, mask_ratio=0.3):\n",
        "        \"\"\"Mask frames with high motion (keyframes)\"\"\"\n",
        "        if len(frame_boxes) < 3: \n",
        "            return []\n",
        "        motion_scores = []\n",
        "        frame_indices = sorted(frame_boxes.keys())\n",
        "        for i in range(1, len(frame_indices) - 1):\n",
        "            prev_frame, curr_frame = frame_indices[i-1], frame_indices[i]\n",
        "            if not frame_boxes.get(prev_frame) or not frame_boxes.get(curr_frame): \n",
        "                continue\n",
        "            try:\n",
        "                prev_box, curr_box = frame_boxes[prev_frame][0], frame_boxes[curr_frame][0]\n",
        "                prev_cx, prev_cy = (prev_box['x1'] + prev_box['x2']) / 2, (prev_box['y1'] + prev_box['y2']) / 2\n",
        "                curr_cx, curr_cy = (curr_box['x1'] + curr_box['x2']) / 2, (curr_box['y1'] + curr_box['y2']) / 2\n",
        "                motion = np.sqrt((curr_cx - prev_cx)**2 + (curr_cy - prev_cy)**2)\n",
        "                motion_scores.append((curr_frame, motion))\n",
        "            except (IndexError, KeyError): \n",
        "                continue\n",
        "        if not motion_scores: \n",
        "            return FrameMaskingStrategy.random_mask(len(frame_indices), mask_ratio)\n",
        "        motion_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "        num_mask = max(1, int(len(motion_scores) * mask_ratio))\n",
        "        return sorted([frame for frame, _ in motion_scores[:num_mask]])\n",
        "\n",
        "print(\"Masking strategies loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a626e20",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a626e20",
        "outputId": "1815a62e-1e3d-4203-c87c-932d001b1ddc",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "# ============================================\n",
        "# 2. TEMPORAL INTERPOLATION\n",
        "# ============================================\n",
        "def interpolate_boxes(frame_boxes, masked_frames, method='cubic'):\n",
        "    \"\"\"Interpolate bounding boxes for masked frames\"\"\"\n",
        "    all_frame_indices = sorted(frame_boxes.keys())\n",
        "    visible_frames = [f for f in all_frame_indices if f not in masked_frames]\n",
        "    if len(visible_frames) < 2: \n",
        "        return {}, all_frame_indices\n",
        "    ground_truth = {}\n",
        "    visible_data = [(f, frame_boxes[f][0]) for f in visible_frames if frame_boxes[f] and len(frame_boxes[f]) > 0]\n",
        "    if len(visible_data) < 2: \n",
        "        return {}, visible_frames\n",
        "    try:\n",
        "        frames = [d[0] for d in visible_data]\n",
        "        x1_vals, y1_vals = [d[1]['x1'] for d in visible_data], [d[1]['y1'] for d in visible_data]\n",
        "        x2_vals, y2_vals = [d[1]['x2'] for d in visible_data], [d[1]['y2'] for d in visible_data]\n",
        "        kind = 'linear'\n",
        "        f_x1 = interp1d(frames, x1_vals, kind=kind, bounds_error=False, fill_value=(x1_vals[0], x1_vals[-1]))\n",
        "        f_y1 = interp1d(frames, y1_vals, kind=kind, bounds_error=False, fill_value=(y1_vals[0], y1_vals[-1]))\n",
        "        f_x2 = interp1d(frames, x2_vals, kind=kind, bounds_error=False, fill_value=(x2_vals[0], x2_vals[-1]))\n",
        "        f_y2 = interp1d(frames, y2_vals, kind=kind, bounds_error=False, fill_value=(y2_vals[0], y2_vals[-1]))\n",
        "        for frame_idx in masked_frames:\n",
        "            if frame_idx in frame_boxes:\n",
        "                ground_truth[frame_idx] = [{\n",
        "                    'frame': frame_idx,\n",
        "                    'x1': int(np.clip(f_x1(frame_idx), 0, 10000)), \n",
        "                    'y1': int(np.clip(f_y1(frame_idx), 0, 10000)),\n",
        "                    'x2': int(np.clip(f_x2(frame_idx), 0, 10000)), \n",
        "                    'y2': int(np.clip(f_y2(frame_idx), 0, 10000))\n",
        "                }]\n",
        "    except Exception as e:\n",
        "        print(f\"Interpolation failed: {e}\")\n",
        "        return {}, visible_frames\n",
        "    return ground_truth, visible_frames\n",
        "\n",
        "print(\"Temporal interpolation function loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bbea54f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bbea54f",
        "outputId": "49e8fc2d-c009-4f61-9bc6-5eb1a8a4936d",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "# ============================================\n",
        "# 3. REMOVE DUPLICATE BOXES\n",
        "# ============================================\n",
        "def remove_duplicate_boxes(boxes, iou_threshold=0.95):\n",
        "    \"\"\"Remove duplicate boxes based on IoU threshold\"\"\"\n",
        "    if len(boxes) <= 1: \n",
        "        return boxes\n",
        "    \n",
        "    def calculate_iou(box1, box2):\n",
        "        \"\"\"Calculate Intersection over Union (IoU) between two boxes\"\"\"\n",
        "        x1_min, y1_min, x1_max, y1_max = box1\n",
        "        x2_min, y2_min, x2_max, y2_max = box2\n",
        "        inter_x_min, inter_y_min = max(x1_min, x2_min), max(y1_min, y2_min)\n",
        "        inter_x_max, inter_y_max = min(x1_max, x2_max), min(y1_max, y2_max)\n",
        "        if inter_x_max < inter_x_min or inter_y_max < inter_y_min: \n",
        "            return 0.0\n",
        "        inter_area = (inter_x_max - inter_x_min) * (inter_y_max - inter_y_min)\n",
        "        box1_area = (x1_max - x1_min) * (y1_max - y1_min)\n",
        "        box2_area = (x2_max - x2_min) * (y2_max - y2_min)\n",
        "        union_area = box1_area + box2_area - inter_area\n",
        "        return inter_area / union_area if union_area > 0 else 0.0\n",
        "    \n",
        "    boxes_xyxy = [(bb['x1'], bb['y1'], bb['x2'], bb['y2']) for bb in boxes]\n",
        "    keep = [True] * len(boxes)\n",
        "    for i in range(len(boxes)):\n",
        "        if not keep[i]: \n",
        "            continue\n",
        "        for j in range(i + 1, len(boxes)):\n",
        "            if not keep[j]: \n",
        "                continue\n",
        "            iou = calculate_iou(boxes_xyxy[i], boxes_xyxy[j])\n",
        "            if iou > iou_threshold:\n",
        "                area_i = (boxes[i]['x2'] - boxes[i]['x1']) * (boxes[i]['y2'] - boxes[i]['y1'])\n",
        "                area_j = (boxes[j]['x2'] - boxes[j]['x1']) * (boxes[j]['y2'] - boxes[j]['y1'])\n",
        "                if area_i >= area_j: \n",
        "                    keep[j] = False\n",
        "                else: \n",
        "                    keep[i] = False\n",
        "                    break\n",
        "    return [boxes[i] for i in range(len(boxes)) if keep[i]]\n",
        "\n",
        "print(\"Duplicate removal function loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb385d0a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb385d0a",
        "outputId": "63ab58c9-2d7b-41b9-9fd0-8c512791cc04",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "# ============================================\n",
        "# 4. ENHANCED FRAME EXTRACTION (UPDATED WITH HNM)\n",
        "# ============================================\n",
        "\n",
        "def extract_frames_with_masking(\n",
        "    video_id,\n",
        "    ann_dict,\n",
        "    mode=\"train\",\n",
        "    augmentation_id=0,\n",
        "    mask_strategy='random',\n",
        "    mask_ratio=0.3\n",
        "):\n",
        "    \"\"\"\n",
        "    Extract frames + labels with masked frame augmentation\n",
        "    and Hard Negative Mining (add background frames)\n",
        "    \"\"\"\n",
        "    video_dir = os.path.join(config.SAMPLES_DIR, video_id)\n",
        "    video_path = os.path.join(video_dir, \"drone_video.mp4\")\n",
        "\n",
        "    if not os.path.exists(video_path):\n",
        "        return {'status': 'missing_video', 'video_id': video_id}\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        cap.release()\n",
        "        return {'status': 'cannot_open', 'video_id': video_id}\n",
        "\n",
        "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "\n",
        "    # Build bbox_dict with deduplication\n",
        "    bbox_dict = {}\n",
        "    dup_removed = 0\n",
        "    for interval in ann_dict.get(video_id, {}).get(\"annotations\", []):\n",
        "        for bb in interval.get(\"bboxes\", []):\n",
        "            bbox_dict.setdefault(bb[\"frame\"], []).append(bb)\n",
        "    for frame_idx in bbox_dict:\n",
        "        original_count = len(bbox_dict[frame_idx])\n",
        "        bbox_dict[frame_idx] = remove_duplicate_boxes(bbox_dict[frame_idx], iou_threshold=0.95)\n",
        "        dup_removed += original_count - len(bbox_dict[frame_idx])\n",
        "\n",
        "    # Apply masking strategy\n",
        "    masked_frames = []\n",
        "    ground_truth = {}\n",
        "    if config.ENABLE_MASKING and mask_ratio > 0 and len(bbox_dict) > 4:\n",
        "        masker = FrameMaskingStrategy()\n",
        "        frame_indices = sorted(bbox_dict.keys())\n",
        "        num_frames_with_labels = len(frame_indices)\n",
        "        if mask_strategy == 'random':\n",
        "            masked_idx_list = masker.random_mask(num_frames_with_labels, mask_ratio)\n",
        "        elif mask_strategy == 'span':\n",
        "            masked_idx_list = masker.span_mask(num_frames_with_labels, mask_ratio)\n",
        "        elif mask_strategy == 'keyframe':\n",
        "            masked_frames = masker.keyframe_mask(bbox_dict, mask_ratio)\n",
        "            masked_idx_list = []\n",
        "        else:\n",
        "            masked_idx_list = []\n",
        "        if masked_idx_list:\n",
        "            masked_frames = [frame_indices[i] for i in masked_idx_list if i < len(frame_indices)]\n",
        "        if masked_frames:\n",
        "            ground_truth, _ = interpolate_boxes(bbox_dict, masked_frames, method='cubic')\n",
        "\n",
        "    # Output directories\n",
        "    if mode == \"train\":\n",
        "        img_out = os.path.join(config.WORK_DIR, 'train', 'images')\n",
        "        lbl_out = os.path.join(config.WORK_DIR, 'train', 'labels')\n",
        "    else:\n",
        "        img_out = os.path.join(config.WORK_DIR, 'val', 'images')\n",
        "        lbl_out = os.path.join(config.WORK_DIR, 'val', 'labels')\n",
        "\n",
        "    saved = 0\n",
        "    masked_count = 0\n",
        "    idx = 0\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Only process frames according to FRAME_STEP\n",
        "            if idx % config.FRAME_STEP == 0:\n",
        "\n",
        "                # CASE 1: POSITIVE FRAME (exists in annotation)\n",
        "                if idx in bbox_dict:\n",
        "                    img_name = f\"{video_id}_aug{augmentation_id:04d}_frame_{idx:06d}.{config.IMG_EXT}\"\n",
        "                    img_path = os.path.join(img_out, img_name)\n",
        "                    txt_name = f\"{video_id}_aug{augmentation_id:04d}_frame_{idx:06d}.txt\"\n",
        "                    txt_path = os.path.join(lbl_out, txt_name)\n",
        "\n",
        "                    if idx in masked_frames and idx in ground_truth:\n",
        "                        boxes_to_save = ground_truth[idx]\n",
        "                        masked_count += 1\n",
        "                    else:\n",
        "                        boxes_to_save = bbox_dict[idx]\n",
        "\n",
        "                    if boxes_to_save:\n",
        "                        if not cv2.imwrite(img_path, frame):\n",
        "                            continue\n",
        "                        lines = []\n",
        "                        for bb in boxes_to_save:\n",
        "                            x1, y1, x2, y2 = bb[\"x1\"], bb[\"y1\"], bb[\"x2\"], bb[\"y2\"]\n",
        "                            if x2 <= x1 or y2 <= y1: \n",
        "                                continue\n",
        "                            x1, y1, x2, y2 = max(0, x1), max(0, y1), min(w, x2), min(h, y2)\n",
        "                            cx, cy = (x1 + x2) / 2 / w, (y1 + y2) / 2 / h\n",
        "                            bw, bh = (x2 - x1) / w, (y2 - y1) / h\n",
        "                            if not (0 <= cx <= 1 and 0 <= cy <= 1 and 0 < bw <= 1 and 0 < bh <= 1): \n",
        "                                continue\n",
        "                            lines.append(f\"0 {cx:.6f} {cy:.6f} {bw:.6f} {bh:.6f}\")\n",
        "\n",
        "                        with open(txt_path, \"w\") as f:\n",
        "                            f.write(\"\\n\".join(lines))\n",
        "                        saved += 1\n",
        "\n",
        "                # CASE 2: HARD NEGATIVE MINING (add background frames)\n",
        "                # Only add background frames for TRAIN set\n",
        "                elif mode == \"train\" and random.random() < config.BACKGROUND_FRAME_RATIO:\n",
        "                    img_name = f\"{video_id}_aug{augmentation_id:04d}_frame_{idx:06d}.{config.IMG_EXT}\"\n",
        "                    img_path = os.path.join(img_out, img_name)\n",
        "                    txt_name = f\"{video_id}_aug{augmentation_id:04d}_frame_{idx:06d}.txt\"\n",
        "                    txt_path = os.path.join(lbl_out, txt_name)\n",
        "\n",
        "                    if cv2.imwrite(img_path, frame):\n",
        "                        # Write empty label file\n",
        "                        with open(txt_path, \"w\") as f:\n",
        "                            f.write(\"\")\n",
        "                        saved += 1  # Still count as saved\n",
        "\n",
        "            idx += 1\n",
        "    finally:\n",
        "        cap.release()\n",
        "\n",
        "    return {\n",
        "        'status': 'success', \n",
        "        'video_id': video_id, \n",
        "        'aug_id': augmentation_id,\n",
        "        'frames_saved': saved, \n",
        "        'masked_frames': masked_count, \n",
        "        'duplicates_removed': dup_removed\n",
        "    }\n",
        "\n",
        "print(\"Frame extraction function loaded (V2: HNM enabled)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edbe11d1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edbe11d1",
        "outputId": "e3c4110e-6a23-4141-fd44-065263e36531",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "# ============================================\n",
        "# 5. CURRICULUM LEARNING CONTROLLER\n",
        "# ============================================\n",
        "\n",
        "class CurriculumController:\n",
        "    \"\"\"Control curriculum learning across epochs\"\"\"\n",
        "    \n",
        "    def __init__(self, curriculum_config):\n",
        "        self.curriculum = curriculum_config\n",
        "        self.phases = sorted(curriculum_config.items(), key=lambda x: x[1]['epochs'][0])\n",
        "    \n",
        "    def get_phase(self, epoch):\n",
        "        \"\"\"Get current phase for given epoch\"\"\"\n",
        "        for phase_name, phase_config in self.phases:\n",
        "            start_epoch, end_epoch = phase_config['epochs']\n",
        "            if start_epoch <= epoch < end_epoch:\n",
        "                return phase_name, phase_config\n",
        "        if self.phases: \n",
        "            return self.phases[-1][0], self.phases[-1][1]\n",
        "        return None, None\n",
        "    \n",
        "    def get_config(self, epoch):\n",
        "        \"\"\"Get configuration for given epoch\"\"\"\n",
        "        phase_name, phase_config = self.get_phase(epoch)\n",
        "        if phase_config is None: \n",
        "            return {'phase': 'unknown', 'mask_ratio': 0.0, 'strategy': 'random'}\n",
        "        return {\n",
        "            'phase': phase_name, \n",
        "            'mask_ratio': phase_config['mask_ratio'], \n",
        "            'strategy': phase_config['strategy']\n",
        "        }\n",
        "    \n",
        "    def print_schedule(self):\n",
        "        \"\"\"Print curriculum learning schedule\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60 + \"\\nCURRICULUM LEARNING SCHEDULE (FOR DATA GENERATION)\\n\" + \"=\"*60)\n",
        "        for phase_name, phase_config in self.phases:\n",
        "            start, end = phase_config['epochs']\n",
        "            print(f\"\\n{phase_name.upper()}: (Reference for Epochs {start}-{end})\")\n",
        "            print(f\"  Mask Ratio: {phase_config['mask_ratio']*100:.0f}%\")\n",
        "            print(f\"  Strategy: {phase_config['strategy']}\")\n",
        "            print(f\"  Augmentations: {config.NUM_AUGMENTATIONS_PER_PHASE} versions\")\n",
        "        print(f\"\\n  Background HNM Ratio: {config.BACKGROUND_FRAME_RATIO*100:.0f}% (for all phases)\")\n",
        "        print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "print(\"Curriculum controller loaded\")\n",
        "\n",
        "# ============================================\n",
        "# MODEL ANALYSIS UTILITY\n",
        "# ============================================\n",
        "def analyze_model(model_path):\n",
        "    \"\"\"Detailed model analysis\"\"\"\n",
        "    print(\"\\n\" + \"=\"*60 + \"\\nMODEL ANALYSIS\\n\" + \"=\"*60)\n",
        "    model = YOLO(model_path)\n",
        "    optimizer = ModelOptimizer(model)\n",
        "    params = optimizer.count_parameters()\n",
        "    print(\"\\nLayer-wise Parameter Count:\")\n",
        "    print(\"-\" * 60)\n",
        "    layer_params = {}\n",
        "    for name, module in model.model.named_modules():\n",
        "        if len(list(module.children())) == 0:\n",
        "            num_params = sum(p.numel() for p in module.parameters())\n",
        "            if num_params > 0:\n",
        "                layer_type = type(module).__name__\n",
        "                layer_params.setdefault(layer_type, {'count': 0, 'params': 0})\n",
        "                layer_params[layer_type]['count'] += 1\n",
        "                layer_params[layer_type]['params'] += num_params\n",
        "    sorted_layers = sorted(layer_params.items(), key=lambda x: x[1]['params'], reverse=True)\n",
        "    for layer_type, info in sorted_layers[:10]:\n",
        "        print(f\"   {layer_type:20s}: {info['count']:3d} layers, {info['params']:12,d} params \"\n",
        "              f\"({info['params']/params['total']*100:5.2f}%)\")\n",
        "    print(\"-\" * 60 + f\"\\n   {'TOTAL':20s}: {params['total']:,} params\\n\")\n",
        "    print(f\"Parameter Limit Check:\")\n",
        "    if params['total'] <= config.PARAM_LIMIT:\n",
        "        print(f\"   Within limit: {params['total']:,} / {config.PARAM_LIMIT:,}\")\n",
        "    else:\n",
        "        print(f\"   Exceeds limit: {params['total']:,} / {config.PARAM_LIMIT:,}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "print(\"Model analysis function loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d813e32b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d813e32b",
        "outputId": "46a3d6d9-7eb5-4e79-b9eb-07b6e9c1865f",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "# ============================================\n",
        "# 6. MAIN PIPELINE (UPDATED WITH AUGMENTATIONS)\n",
        "# ============================================\n",
        "\n",
        "def main_pipeline():\n",
        "    \"\"\"Main training pipeline\"\"\"\n",
        "\n",
        "    print(\"ENHANCED YOLO WORLD TRAINING PIPELINE (V2: HNM + AUG)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Load annotations & Split train/val\n",
        "    with open(config.ANNOTATIONS_PATH, \"r\") as f:\n",
        "        annotations = json.load(f)\n",
        "    video_ids = [a[\"video_id\"] for a in annotations]\n",
        "    ann_dict = {a[\"video_id\"]: a for a in annotations}\n",
        "    random.seed(42)\n",
        "    random.shuffle(video_ids)\n",
        "    split_idx = int(len(video_ids) * config.TRAIN_RATIO)\n",
        "    train_videos, val_videos = video_ids[:split_idx], video_ids[split_idx:]\n",
        "    print(f\"Loaded {len(video_ids)} videos (Train: {len(train_videos)}, Val: {len(val_videos)})\")\n",
        "\n",
        "    # Setup curriculum\n",
        "    curriculum = CurriculumController(config.CURRICULUM)\n",
        "    curriculum.print_schedule()  # Will print HNM ratio as well\n",
        "\n",
        "    # Create output directories\n",
        "    os.makedirs(config.WORK_DIR, exist_ok=True)\n",
        "    for subdir in ['train/images', 'train/labels', 'val/images', 'val/labels']:\n",
        "        os.makedirs(os.path.join(config.WORK_DIR, subdir), exist_ok=True)\n",
        "\n",
        "    # Data generation (HNM already integrated into extract function)\n",
        "    print(f\"\\nPreparing all data augmentations in one go (HNM enabled)...\")\n",
        "    futures, stats_list = [], []\n",
        "    global_aug_id_counter = 0\n",
        "    with ThreadPoolExecutor(max_workers=config.NUM_WORKERS) as ex:\n",
        "        # 1. Train data\n",
        "        for phase_name, phase_config in curriculum.phases:\n",
        "            print(f\"  -> Submitting jobs for Phase: {phase_name.upper()}\")\n",
        "            mask_ratio, mask_strategy = phase_config['mask_ratio'], phase_config['strategy']\n",
        "            for vid in train_videos:\n",
        "                for _ in range(config.NUM_AUGMENTATIONS_PER_PHASE):\n",
        "                    futures.append(ex.submit(\n",
        "                        extract_frames_with_masking,\n",
        "                        vid, ann_dict, \"train\", global_aug_id_counter, mask_strategy, mask_ratio\n",
        "                    ))\n",
        "                    global_aug_id_counter += 1\n",
        "        # 2. Val data\n",
        "        print(f\"\\n  -> Submitting jobs for VALIDATION data (No masking, No HNM)\")\n",
        "        for vid in val_videos:\n",
        "            futures.append(ex.submit(\n",
        "                extract_frames_with_masking,\n",
        "                vid, ann_dict, \"val\", 0, 'random', 0.0\n",
        "            ))\n",
        "        # 3. Collect results\n",
        "        print(f\"\\nWaiting for {len(futures)} total jobs to complete...\")\n",
        "        for i, fut in enumerate(as_completed(futures), 1):\n",
        "            result = fut.result()\n",
        "            stats_list.append(result)\n",
        "            if i % 100 == 0 or i == len(futures):\n",
        "                if result['status'] == 'success':\n",
        "                    msg = (f\"[{i}/{len(futures)}] {result['video_id']}_aug{result['aug_id']:04d}: \"\n",
        "                           f\"{result['frames_saved']} frames\")\n",
        "                    if result['masked_frames'] > 0: \n",
        "                        msg += f\" ({result['masked_frames']} masked)\"\n",
        "                    print(msg)\n",
        "                else: \n",
        "                    print(f\"[{i}/{len(futures)}] {result['video_id']}: {result['status']}\")\n",
        "\n",
        "    # Print statistics\n",
        "    success_stats = [s for s in stats_list if s['status'] == 'success']\n",
        "    total_frames = sum(s['frames_saved'] for s in success_stats)\n",
        "    total_masked = sum(s['masked_frames'] for s in success_stats)\n",
        "    print(f\"\\n{'='*60}\\nTOTAL DATASET STATISTICS (ALL PHASES MIXED):\\n\"\n",
        "          f\"   Total frames saved: {total_frames}\\n\"\n",
        "          f\"   Total masked frames: {total_masked} ({total_masked/max(1,total_frames)*100:.1f}%)\\n\"\n",
        "          f\"   Total train augmentations: {global_aug_id_counter}\\n{'='*60}\")\n",
        "\n",
        "    # Create data.yaml\n",
        "    data_yaml = {\n",
        "        \"train\": os.path.abspath(os.path.join(config.WORK_DIR, 'train', 'images')),\n",
        "        \"val\": os.path.abspath(os.path.join(config.WORK_DIR, 'val', 'images')),\n",
        "        \"nc\": 1, \n",
        "        \"names\": config.CLASS_NAMES\n",
        "    }\n",
        "    data_path = os.path.join(config.WORK_DIR, \"data.yaml\")\n",
        "    with open(data_path, \"w\") as f: \n",
        "        yaml.dump(data_yaml, f)\n",
        "    print(f\"\\ndata.yaml created at: {data_path}\")\n",
        "\n",
        "    # Training\n",
        "    print(\"\\n\" + \"=\"*60 + \"\\nSTARTING TRAINING (V2)\\n\" + \"=\"*60)\n",
        "    model = YOLO(config.MODEL_WEIGHTS)\n",
        "\n",
        "    # Callback\n",
        "    monitor = CurriculumController(config.CURRICULUM)\n",
        "    def on_epoch_end(trainer):\n",
        "        epoch = trainer.epoch + 1\n",
        "        phase_config = monitor.get_config(epoch)\n",
        "        if epoch == 1 or (epoch) % 5 == 0 or epoch == trainer.epochs:\n",
        "            print(f\"\\n-- Epoch {epoch}/{trainer.epochs} -- \"\n",
        "                  f\"Curriculum Phase (Reference): {phase_config['phase']} --\")\n",
        "    \n",
        "    model.add_callback(\"on_epoch_end\", on_epoch_end)\n",
        "    results = model.train(\n",
        "        data=data_path,\n",
        "        epochs=15,              # Maximize available epochs\n",
        "        imgsz=896,              # Reduce to 640 or 896. Don't use 1024 if GPU is weak, it will train slowly\n",
        "        batch=36,               # Moderate batch size\n",
        "\n",
        "        # FREEZE STRATEGY (Important)\n",
        "        freeze=0,               # Freeze first 10 layers (Backbone)\n",
        "\n",
        "        # OPTIMIZE CONVERGENCE SPEED\n",
        "        lr0=0.01,               # Higher initial learning rate\n",
        "        lrf=0.1,                # Less LR reduction at end of cycle\n",
        "        optimizer=\"AdamW\",      # AdamW converges faster than SGD\n",
        "        warmup_epochs=1.0,      # Shorter warmup (only 1 epoch or 0.5)\n",
        "\n",
        "        # DISABLE DIFFICULT AUGMENTATIONS (Let model learn basics quickly)\n",
        "        erasing=0.0,            # IMPORTANT: Disable YOLO Erasing since we already mask manually\n",
        "        dropout=0.0,\n",
        "        mosaic=0.1,             # Disable mosaic (image stitching makes model harder)\n",
        "        mixup=0.1,              # Disable mixup\n",
        "        hsv_h=0.03,             # Light color adjustment only\n",
        "        hsv_s=0.3,              # Keep saturation unchanged\n",
        "        hsv_v=0.3,              # Keep brightness unchanged\n",
        "        degrees=0.1,            # No rotation\n",
        "        translate=0.0,          # Light translation\n",
        "        scale=0.5,              # Light zoom in/out\n",
        "\n",
        "        patience=5,\n",
        "        save_period=5,\n",
        "        workers=8,\n",
        "        close_mosaic=10,\n",
        "        # Other settings\n",
        "        project=os.path.join(config.WORK_DIR, \"runs\"),\n",
        "        name=\"fast_finetune_yolo\",\n",
        "        exist_ok=True,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60 + \"\\nTRAINING COMPLETE!\\n\" + \"=\"*60)\n",
        "    best_model_path = os.path.join(model.trainer.save_dir, 'weights', 'best.pt')\n",
        "    print(f\"Best model: {best_model_path}\")\n",
        "\n",
        "    return best_model_path\n",
        "\n",
        "print(\"Main pipeline function loaded (V2: HSV Augs)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cafc306",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cafc306",
        "outputId": "67ffa52e-ae32-4c66-e248-0b4abcfce3cb",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "# ============================================\n",
        "# 7. INFERENCE\n",
        "# ============================================\n",
        "\n",
        "def run_inference(model_path, test_root, output_json, conf=0.35, iou=0.55):\n",
        "    \"\"\"Run inference on test set\"\"\"\n",
        "    print(\"\\n\" + \"=\"*60 + \"\\nRUNNING INFERENCE\\n\" + \"=\"*60)\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model = YOLO(model_path)\n",
        "    video_dirs = sorted([d for d in os.listdir(test_root) if os.path.isdir(os.path.join(test_root, d))])\n",
        "    submission = []\n",
        "    for i, vid in enumerate(video_dirs, 1):\n",
        "        video_path = os.path.join(test_root, vid, \"drone_video.mp4\")\n",
        "        if not os.path.exists(video_path): \n",
        "            continue\n",
        "        bboxes_per_frame = []\n",
        "        results = model.predict(\n",
        "            source=video_path, conf=conf, iou=iou, imgsz=896,\n",
        "            stream=True, verbose=False, device=device\n",
        "        )\n",
        "        frame_idx = 0\n",
        "        for r in results:\n",
        "            if r.boxes is not None and len(r.boxes) > 0:\n",
        "                for (x1, y1, x2, y2) in r.boxes.xyxy.cpu().numpy():\n",
        "                    bboxes_per_frame.append({\n",
        "                        \"frame\": frame_idx, \n",
        "                        \"x1\": int(x1), \n",
        "                        \"y1\": int(y1), \n",
        "                        \"x2\": int(x2), \n",
        "                        \"y2\": int(y2)\n",
        "                    })\n",
        "            frame_idx += 1\n",
        "        submission.append({\n",
        "            \"video_id\": vid, \n",
        "            \"detections\": [{\"bboxes\": bboxes_per_frame}] if bboxes_per_frame else []\n",
        "        })\n",
        "        print(f\"[{i}/{len(video_dirs)}] {vid}: {len(bboxes_per_frame)} detections\")\n",
        "    with open(output_json, \"w\") as f:\n",
        "        json.dump(submission, f, indent=2, ensure_ascii=False)\n",
        "    print(f\"\\nSaved submission to: {output_json}\")\n",
        "\n",
        "print(\"Inference function loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NGogrQZGjE36",
      "metadata": {
        "id": "NGogrQZGjE36"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6efd56fb",
      "metadata": {
        "id": "6efd56fb",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# 8. MAIN EXECUTION\n",
        "# ============================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\"\"\n",
        "    YOLO WORLD + MASKED + CURRICULUM (V2: HNM + AUG)\n",
        "    Enhanced Pipeline for Video Object Detection\n",
        "    \"\"\")\n",
        "    # Check GPU\n",
        "    print(f\"Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"    GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "    # Configure paths\n",
        "    config.DATASET_ROOT = \"train\"\n",
        "    TEST_ROOT = \"public_test/samples\"\n",
        "    OUTPUT_JSON = \"submission_optimized_v2.json\"  # New file name\n",
        "\n",
        "    # Run main pipeline\n",
        "    try:\n",
        "        best_model_path = main_pipeline()\n",
        "\n",
        "        # Analyze best model\n",
        "        if best_model_path:\n",
        "            analyze_model(best_model_path)\n",
        "\n",
        "        # Run inference\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        if os.path.exists(TEST_ROOT) and best_model_path:\n",
        "            print(\"Auto-running inference on test set...\")\n",
        "            run_inference(\n",
        "                model_path=best_model_path,\n",
        "                test_root=TEST_ROOT,\n",
        "                output_json=OUTPUT_JSON,\n",
        "                conf=0.35  # Keep conf=0.35 for comparison\n",
        "            )\n",
        "        else:\n",
        "            print(\"Skipping inference: Test set path not found or training failed.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn error occurred in the pipeline: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
