{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e628504",
   "metadata": {},
   "source": [
    "### Set Seed Cố Định"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972ad50f",
   "metadata": {},
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Đặt seed cố định của đội bạn\n",
    "seed_everything(42) # [cite: 491]\n",
    "print(\"Seed set to 42 for reproducibility.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff699d0",
   "metadata": {},
   "source": [
    "## Nạp Mô Hình và Tài Nguyên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd19b1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLOWorld\n",
    "\n",
    "start_load = time.time()\n",
    "\n",
    "model_path = \"/code/saved_models/best.pt\"\n",
    "model = YOLOWorld(model_path)\n",
    "model.set_classes([\"target\"])\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "end_load = time.time()\n",
    "print(f\"Model Load Time (ms): {int((end_load - start_load) * 1000)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543b8dd1",
   "metadata": {},
   "source": [
    "## Đọc Nội Dung Các Test Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a1e05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "DATA_ROOT = \"/data/samples\"\n",
    "test_cases = glob.glob(os.path.join(DATA_ROOT, \"*\", \"drone_video.mp4\"))\n",
    "print(f\"Found {len(test_cases)} test videos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76816893",
   "metadata": {},
   "source": [
    "## Thực Hiện Dự Đoán và In Ra Kết Quả/Thời Gian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5db548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "all_predicted_time = [] \n",
    "all_result = []         \n",
    "\n",
    "OUTPUT_TIME_FILE = \"/result/jupyter_time_submission.csv\"\n",
    "OUTPUT_JSON_FILE = \"/result/jupyter_submission.json\" \n",
    "\n",
    "def write_predict_file(results, path):\n",
    "    submission = []\n",
    "    for vid, bboxes in results:\n",
    "        submission.append({\n",
    "            \"video_id\": vid,\n",
    "            \"detections\": [{\"bboxes\": bboxes}] if bboxes else []\n",
    "        })\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(submission, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "def write_time_file(times, path):\n",
    "    df = pd.DataFrame(times, columns=[\"id\", \"answer\", \"time\"])\n",
    "    df.to_csv(path, index=False)\n",
    "\n",
    "\n",
    "for file_path in test_cases:\n",
    "    video_id = os.path.basename(os.path.dirname(file_path)) # Trích xuất ID\n",
    "    \n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    bboxes_per_frame = []\n",
    "    frame_idx = 0\n",
    "    \n",
    "    t1 = time.time()\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        results = model.predict(\n",
    "            source=frame_rgb,\n",
    "            conf=0.35, iou=0.55, imgsz=896, verbose=False, device=device\n",
    "        )\n",
    "        \n",
    "        result_box = None\n",
    "        for r in results:\n",
    "            if r.boxes is not None and len(r.boxes) > 0:\n",
    "                box_xyxy = r.boxes.xyxy.cpu().numpy()[0]\n",
    "                x1, y1, x2, y2 = map(int, box_xyxy)\n",
    "                result_box = [x1, y1, x2, y2]\n",
    "                break\n",
    "        \n",
    "        if result_box is not None:\n",
    "            x1, y1, x2, y2 = result_box\n",
    "            bboxes_per_frame.append({\n",
    "                \"frame\": frame_idx,\n",
    "                \"x1\": x1, \"y1\": y1, \"x2\": x2, \"y2\": y2\n",
    "            })\n",
    "            \n",
    "        frame_idx += 1\n",
    "        \n",
    "    cap.release()\n",
    "    \n",
    "    t2 = time.time()\n",
    "    predicted_time = int((t2 - t1) * 1000)\n",
    "    all_predicted_time.append((video_id, len(bboxes_per_frame), predicted_time))\n",
    "    all_result.append((video_id, bboxes_per_frame))\n",
    "\n",
    "write_predict_file(all_result, OUTPUT_JSON_FILE) \n",
    "write_time_file(all_predicted_time, OUTPUT_TIME_FILE)\n",
    "\n",
    "print(f\"Jupyter results saved to {OUTPUT_JSON_FILE} and {OUTPUT_TIME_FILE}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr_corrector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
